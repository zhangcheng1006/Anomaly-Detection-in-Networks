{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator import *\n",
    "from NetEMD_shiwen import *\n",
    "import numpy as np\n",
    "import community\n",
    "import networkx as nx\n",
    "from utils import generate_null_model, comm_eigenvectors, partition_graph\n",
    "from scipy.stats import norm\n",
    "from com_detection import augmentation\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 7 anomalies...\n",
      "The 1th anomaly...\n",
      "0\n",
      "15\n",
      "Adding rings...\n",
      "The 2th anomaly...\n",
      "15\n",
      "20\n",
      "Adding paths...\n",
      "[182 964 721  63 521]\n",
      "The 3th anomaly...\n",
      "20\n",
      "25\n",
      "Adding rings...\n",
      "The 4th anomaly...\n",
      "25\n",
      "38\n",
      "Adding rings...\n",
      "The 5th anomaly...\n",
      "38\n",
      "46\n",
      "Adding stars...\n",
      "The 6th anomaly...\n",
      "46\n",
      "60\n",
      "Adding stars...\n",
      "The 7th anomaly...\n",
      "60\n",
      "73\n",
      "Adding stars...\n"
     ]
    }
   ],
   "source": [
    "graph = ER_generator(n=1000, seed=None)\n",
    "graph = draw_anomalies(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_strength(g, strength_type=None, normalize=False):\n",
    "    if strength_type == 'in':\n",
    "        strength = dict(g.in_degree(weight='weight'))\n",
    "    elif strength_type == 'out':\n",
    "        strength = dict(g.out_degree(weight='weight'))\n",
    "    else:\n",
    "        strength = dict(g.degree(weight='weight'))\n",
    "    if normalize:\n",
    "        values = np.array(list(strength.values()))\n",
    "        normed = values / np.std(values)\n",
    "    return {node: v for node, v in zip(strength.keys(), normed)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_strength_score(g, references, null_samples):\n",
    "    \"\"\"Compute one statistics on a graph(subgraph)\n",
    "    \"\"\"\n",
    "    # in strength\n",
    "    obs_stat = compute_strength(g, 'in')\n",
    "    ref_stats = [compute_strength(ref, 'in', normalize=True) for ref in references]\n",
    "    null_stats = [compute_strength(n_samp, 'in', normalize=True) for n_samp in null_samples]\n",
    "    try:\n",
    "        in_strength_1, in_strength_2 = NetEMD_score(obs_stat, ref_stats, null_stats)\n",
    "    except:\n",
    "        print(obs_stat)\n",
    "    # out_strength\n",
    "    obs_stat = compute_strength(g, 'out')\n",
    "    ref_stats = [compute_strength(ref, 'out', normalize=True) for ref in references]\n",
    "    null_stats = [compute_strength(n_samp, 'out', normalize=True) for n_samp in null_samples]\n",
    "    out_strength_1, out_strength_2 = NetEMD_score(obs_stat, ref_stats, null_stats)\n",
    "    # in_out_strength\n",
    "    obs_stat = compute_strength(g)\n",
    "    ref_stats = [compute_strength(ref, normalize=True) for ref in references]\n",
    "    null_stats = [compute_strength(n_samp, normalize=True) for n_samp in null_samples]\n",
    "    in_out_strength_1, in_out_strength_2 = NetEMD_score(obs_stat, ref_stats, null_stats)\n",
    "    \n",
    "    return in_strength_1, in_strength_2, out_strength_1, out_strength_2, in_out_strength_1, in_out_strength_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NetEMD_features(graph, num_references=15, num_samples=500, n=10000, p=0.001):\n",
    "    global stats\n",
    "    logging.info(\"partition graph\")\n",
    "    communities = [graph.subgraph(comm_nodes) for comm_nodes in partition_graph(graph)]\n",
    "    logging.info(\"got {} communities\".format(len(communities)))\n",
    "    logging.info(\"generating references\")\n",
    "    references = generate_null_model(num_models=num_references, min_size=5, n=n, p=p)\n",
    "    logging.info(\"generating null samples\")\n",
    "    null_samples = generate_null_model(num_models=num_samples, min_size=5, n=n, p=p)\n",
    "    for comm_idx, community in enumerate(communities):\n",
    "        logging.info(\"computing strength scores for community No.{}\".format(comm_idx))\n",
    "        strength_scores = compute_strength_score(community, references, null_samples)\n",
    "        strength_names = ['in_strength_1', 'in_strength_2', 'out_strength_1', 'out_strength_2', 'in_out_strength_1', 'in_out_strength_2']\n",
    "        for strength_name, strength_score in zip(strength_names, strength_scores):\n",
    "            for node, score in strength_score.items():\n",
    "                assert graph[node].get(strength_name) is None\n",
    "                graph[node][strength_name] = score\n",
    "        logging.info(\"computing motif scores for community No.{}\".format(comm_idx))\n",
    "        motif_scores = compute_motif_score(community, references, null_samples)\n",
    "        for idx in range(13):\n",
    "            motif_score = motif_scores[idx]\n",
    "            motif_id = idx + 4\n",
    "            for score_idx in [1, 2]:\n",
    "                for node, score in motif_score[score_idx-1].items():\n",
    "                    assert graph[node].get('motif_{}_{}'.format(motif_id, score_idx)) is None\n",
    "                    graph[node]['motif_{}_{}'.format(motif_id, score_idx)] = score\n",
    "    logging.info(\"generating augmented graph\")\n",
    "    graph_aug = augmentation(graph)\n",
    "    logging.info(\"partition augmented graph\")\n",
    "    communities_aug = [graph_aug.subgraph(comm_nodes) for comm_nodes in partition_graph(graph_aug)]\n",
    "    logging.info(\"get {} augmented communities\".format(len(communities_aug)))\n",
    "    logging.info(\"generating augmented refrences\")\n",
    "    references_aug = generate_null_model(num_models=num_references, min_size=5, n=n, p=p, augment=True)\n",
    "    logging.info(\"generating augmented null samples\")\n",
    "    null_samples_aug = generate_null_model(num_models=num_samples, min_size=5, n=n, p=p, augment=True)\n",
    "    matrix_names = ['upper', 'lower', 'comb', 'rw']\n",
    "    for comm_idx, community in enumerate(communities_aug):\n",
    "        logging.info(\"computing matrix scores for community No.{}\".format(comm_idx))\n",
    "        matrix_scores = compute_matrix_score(community, references_aug, null_samples_aug) # 4 tuples of (score1, score2)\n",
    "        for matrix_idx, matrix_name in enumerate(matrix_names):\n",
    "            for node in community.nodes():\n",
    "                graph[node]['{}_1'.format(matrix_name)] = matrix_scores[matrix_idx][0][node]\n",
    "                graph[node]['{}_2'.format(matrix_name)] = matrix_scores[matrix_idx][1][node]\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root - INFO - partition graph\n",
      "root - INFO - got 51 communities\n",
      "root - INFO - generating references\n",
      "root - INFO - Generating 1-th null model\n",
      "root - INFO - Partitioning graph\n",
      "root - INFO - Generating 2-th null model\n",
      "root - INFO - Partitioning graph\n",
      "root - INFO - generating null samples\n",
      "root - INFO - Generating 1-th null model\n",
      "root - INFO - Partitioning graph\n",
      "root - INFO - Generating 2-th null model\n",
      "root - INFO - Partitioning graph\n",
      "root - INFO - computing strength scores for community No.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-edeb2f635999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetEMD_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_references\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-3317c5afb7b9>\u001b[0m in \u001b[0;36mNetEMD_features\u001b[0;34m(graph, num_references, num_samples, n, p)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcomm_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommunity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommunities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"computing strength scores for community No.{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomm_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mstrength_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_strength_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommunity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnull_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mstrength_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'in_strength_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in_strength_2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'out_strength_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'out_strength_2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in_out_strength_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in_out_strength_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstrength_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrength_score\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrength_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrength_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-5f717780ef64>\u001b[0m in \u001b[0;36mcompute_strength_score\u001b[0;34m(g, references, null_samples)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mref_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompute_strength\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'out'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mref\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mnull_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompute_strength\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'out'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn_samp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnull_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mout_strength_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_strength_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetEMD_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_stat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnull_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m# in_out_strength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mobs_stat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_strength\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Study/ENSAE/Anomaly-Detection-in-Networks/NetEMD_shiwen.py\u001b[0m in \u001b[0;36mNetEMD_score\u001b[0;34m(obs_stat, ref_stats, null_stats)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# ref_stats, null_stats already normalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# return dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mobs_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_stat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mobs_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "graph = NetEMD_features(graph, num_references=2, num_samples=2, n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
